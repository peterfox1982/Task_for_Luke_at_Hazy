{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict the most likely gender and ethnicity for a given first name in the given data set. Having done a quick bit of research online I found that the best approach would be some kind of LSTM deep learning model. This has the advantage of learning from sequences as it's a kind of RNN. Some of the code is adapted from that contained in the following reference (why re-invent the wheel?!):\n",
    "\n",
    "Deep Learning Gender from name - RNN LSTMs (P R Deepakbabu Github repository):\n",
    "\n",
    "https://github.com/prdeepakbabu/Python/blob/master/Deep%20learning%20gender/Deep%20Learning%20(RNN%20-%20LSTMs)%20Predict%20Gender%20from%20Name.ipynb\n",
    "\n",
    "So let's pre-process our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "maxlen = 30\n",
    "labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove column headers:\n",
    "\n",
    "reader = csv.reader(open('clean_names.csv' , 'rb'))\n",
    "    \n",
    "f=csv.writer(open('clean_names_tidy.csv' , 'wb'))\n",
    "    \n",
    "for line in reader:\n",
    "    if \"gender\" not in line:\n",
    "        f.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      first_name gender            last_name      race  namelen\n",
      "0        shirley      f                adams  hispanic        7\n",
      "1            ana      f               alonso  hispanic        3\n",
      "2         miriam      f               alonzo  hispanic        6\n",
      "3         ivette      f              alvarez  hispanic        6\n",
      "4          saray      f               amador  hispanic        5\n",
      "5         niurka      f              batista  hispanic        6\n",
      "6          maria      f           betancourt  hispanic        5\n",
      "7       merienne      f                blake  hispanic        8\n",
      "8      rosalinda      f                 boyd  hispanic        9\n",
      "9       migdalia      f              braconi  hispanic        8\n",
      "10        marina      f                bueno  hispanic        6\n",
      "11        carmen      f               burgos  hispanic        6\n",
      "12         zaida      f              cabrera  hispanic        5\n",
      "13        lurvin      f             calderon  hispanic        6\n",
      "14       melissa      f             calderon  hispanic        7\n",
      "15       mileyka      f           candelario  hispanic        7\n",
      "16      kimberly      f               cannon  hispanic        8\n",
      "17      ivelisse      f            caraballo  hispanic        8\n",
      "18           ana      f              cardona  hispanic        3\n",
      "19        emilia      f                 carr  hispanic        6\n",
      "20        connie      f              carroll  hispanic        6\n",
      "21          anna      f             castillo  hispanic        4\n",
      "22      samantha      f               castro  hispanic        8\n",
      "23     elizabeth      f            centurion  hispanic        9\n",
      "24          ines      f               coreas  hispanic        4\n",
      "25        djerid      f               corona  hispanic        6\n",
      "26        ivette      f             corporan  hispanic        6\n",
      "27        gloria      f  correa de castrillo  hispanic        6\n",
      "28         linda      f             darienzo  hispanic        5\n",
      "29        josefa      f               davila  hispanic        6\n",
      "...          ...    ...                  ...       ...      ...\n",
      "65466    timothy      m              lambert     white        7\n",
      "65467       todd      m              lambert     white        4\n",
      "65468     victor      m              lambert     white        6\n",
      "65469    zachary      m              lambert     white        7\n",
      "65470      lukas      m     lambert-albright     white        5\n",
      "65471    kenneth      m            lamberton     white        7\n",
      "65472      brent      m              lambeth     white        5\n",
      "65473    timothy      m              lambeth     white        7\n",
      "65474     george      m              lambing     white        6\n",
      "65475       john      m            lambrecht     white        4\n",
      "65476    freeman      m            lambright     white        7\n",
      "65477    michael      m              lambrix     white        7\n",
      "65478    william      m              lambrix     white        7\n",
      "65479     walter      m               lameka     white        6\n",
      "65480    richard      m             lamerton     white        7\n",
      "65481    kenneth      m               lamkin     white        7\n",
      "65482      roger      m               lamkin     white        5\n",
      "65483      danny      m                 lamm     white        5\n",
      "65484      devin      m                 lamm     white        5\n",
      "65485    william      m               lamond     white        7\n",
      "65486      mikel      m               lamoni     white        5\n",
      "65487    william      m             lamonica     white        7\n",
      "65488     andrew      m               lamont     white        6\n",
      "65489      david      m               lamont     white        5\n",
      "65490    stephen      m               lamont     white        7\n",
      "65491    william      m               lamont     white        7\n",
      "65492     george      m           lamontagne     white        6\n",
      "65493   theodore      m           lamontagne     white        8\n",
      "65494     donald      m               lamore     white        6\n",
      "65495    gregory      m            lamoureux      whit        7\n",
      "\n",
      "[65456 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "input = pd.read_csv('clean_names_tidy.csv',header=None)\n",
    "input.columns = ['first_name','gender','last_name','race']\n",
    "input['namelen']= [len(str(i)) for i in input['first_name']]\n",
    "#print (input)\n",
    "input1 = input[(input['namelen'] >= 2) ]\n",
    "print (input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "f     4816\n",
       "m    60639\n",
       "Name: first_name, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1.groupby('gender')['first_name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = input['first_name']\n",
    "gender = input['gender']\n",
    "vocab = set(' '.join([str(i) for i in names]))\n",
    "vocab.add('END')\n",
    "len_vocab = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' ', '-', '.', '0', 'END', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z'])\n",
      "vocab length is  31\n",
      "length of input is  65456\n"
     ]
    }
   ],
   "source": [
    "print(vocab)\n",
    "print(\"vocab length is \",len_vocab)\n",
    "print (\"length of input is \",len(input1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_index = dict((c, i) for i, c in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '-': 1, '.': 2, '0': 3, 'END': 4, 'a': 5, 'c': 6, 'b': 7, 'e': 8, 'd': 9, 'g': 10, 'f': 11, 'i': 12, 'h': 13, 'k': 14, 'j': 15, 'm': 16, 'l': 17, 'o': 18, 'n': 19, 'q': 20, 'p': 21, 's': 22, 'r': 23, 'u': 24, 't': 25, 'w': 26, 'v': 27, 'y': 28, 'x': 29, 'z': 30}\n"
     ]
    }
   ],
   "source": [
    "print(char_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "msk = np.random.rand(len(input1)) < 0.8\n",
    "train = input1[msk]\n",
    "test = input1[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          shirley\n",
      "1              ana\n",
      "2           miriam\n",
      "3           ivette\n",
      "4            saray\n",
      "5           niurka\n",
      "6            maria\n",
      "7         merienne\n",
      "9         migdalia\n",
      "11          carmen\n",
      "12           zaida\n",
      "13          lurvin\n",
      "14         melissa\n",
      "15         mileyka\n",
      "16        kimberly\n",
      "17        ivelisse\n",
      "18             ana\n",
      "19          emilia\n",
      "20          connie\n",
      "23       elizabeth\n",
      "24            ines\n",
      "25          djerid\n",
      "26          ivette\n",
      "27          gloria\n",
      "28           linda\n",
      "29          josefa\n",
      "30        graciela\n",
      "31             ada\n",
      "32        michelle\n",
      "33          angela\n",
      "           ...    \n",
      "65460      michael\n",
      "65461      michael\n",
      "65463      richard\n",
      "65464        roger\n",
      "65465       stacey\n",
      "65466      timothy\n",
      "65467         todd\n",
      "65468       victor\n",
      "65469      zachary\n",
      "65471      kenneth\n",
      "65472        brent\n",
      "65473      timothy\n",
      "65474       george\n",
      "65475         john\n",
      "65477      michael\n",
      "65478      william\n",
      "65479       walter\n",
      "65480      richard\n",
      "65481      kenneth\n",
      "65482        roger\n",
      "65483        danny\n",
      "65484        devin\n",
      "65485      william\n",
      "65487      william\n",
      "65488       andrew\n",
      "65489        david\n",
      "65490      stephen\n",
      "65493     theodore\n",
      "65494       donald\n",
      "65495      gregory\n",
      "Name: first_name, Length: 52154, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#take input upto max and truncate rest\n",
    "#encode to vector space(one hot encoding)\n",
    "#pad 'END' to shorter sequences\n",
    "print (train.first_name)\n",
    "train_X = []\n",
    "trunc_train_name = [str(i)[0:30] for i in train.first_name]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [char_index[j] for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(char_index[\"END\"])\n",
    "    train_X.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52154, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_flag(i):\n",
    "    tmp = np.zeros(39);\n",
    "    tmp[i] = 1\n",
    "    return(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_flag(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take input upto max and truncate rest\n",
    "#encode to vector space(one hot encoding)\n",
    "#add 'END' to shorter sequences\n",
    "#also convert each index to one-hot encoding\n",
    "train_X = []\n",
    "train_Y = []\n",
    "trunc_train_name = [str(i)[0:maxlen] for i in train.first_name]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    train_X.append(tmp)\n",
    "for i in train.gender:\n",
    "    if i == 'm':\n",
    "        train_Y.append([1,0])\n",
    "    else:\n",
    "        train_Y.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52154, 30, 39)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52154, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "#build the model: 2 stacked LSTM\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen,39)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []\n",
    "test_Y = []\n",
    "trunc_test_name = [str(i)[0:maxlen] for i in test.first_name]\n",
    "for i in trunc_test_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    test_X.append(tmp)\n",
    "for i in test.gender:\n",
    "    if i == 'm':\n",
    "        test_Y.append([1,0])\n",
    "    else:\n",
    "        test_Y.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13302, 30, 39)\n",
      "(13302, 2)\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(test_X).shape)\n",
    "print(np.asarray(test_Y).shape)\n",
    "print (maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52154 samples, validate on 13302 samples\n",
      "Epoch 1/3\n",
      "52154/52154 [==============================] - 724s 14ms/step - loss: 0.2762 - acc: 0.9245 - val_loss: 0.2647 - val_acc: 0.9257\n",
      "Epoch 2/3\n",
      "52154/52154 [==============================] - 656s 13ms/step - loss: 0.2565 - acc: 0.9260 - val_loss: 0.2315 - val_acc: 0.9257\n",
      "Epoch 3/3\n",
      "52154/52154 [==============================] - 655s 13ms/step - loss: 0.2242 - acc: 0.9261 - val_loss: 0.2157 - val_acc: 0.9244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2ee31d50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1000\n",
    "model.fit(np.array(train_X), np.array(train_Y),batch_size=batch_size,nb_epoch=3,validation_data=(np.array(test_X), np.array(test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13302/13302 [==============================] - 78s 6ms/step\n",
      "Test score: 0.21567851997079607\n",
      "Test accuracy: 0.9243722748458878\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(np.array(test_X), np.array(test_Y))\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "92% is pretty good for 3 epochs. Let's run a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52154 samples, validate on 13302 samples\n",
      "Epoch 1/15\n",
      "52154/52154 [==============================] - 842s 16ms/step - loss: 0.2117 - acc: 0.9273 - val_loss: 0.2053 - val_acc: 0.9286\n",
      "Epoch 2/15\n",
      "52154/52154 [==============================] - 671s 13ms/step - loss: 0.1972 - acc: 0.9322 - val_loss: 0.1855 - val_acc: 0.9356\n",
      "Epoch 3/15\n",
      "52154/52154 [==============================] - 789s 15ms/step - loss: 0.1779 - acc: 0.9405 - val_loss: 0.1831 - val_acc: 0.9410\n",
      "Epoch 4/15\n",
      "52154/52154 [==============================] - 659s 13ms/step - loss: 0.1674 - acc: 0.9474 - val_loss: 0.1618 - val_acc: 0.9527\n",
      "Epoch 5/15\n",
      "52154/52154 [==============================] - 732s 14ms/step - loss: 0.1519 - acc: 0.9551 - val_loss: 0.1596 - val_acc: 0.9450\n",
      "Epoch 6/15\n",
      "52154/52154 [==============================] - 692s 13ms/step - loss: 0.1385 - acc: 0.9575 - val_loss: 0.1554 - val_acc: 0.9541\n",
      "Epoch 7/15\n",
      "52154/52154 [==============================] - 678s 13ms/step - loss: 0.1317 - acc: 0.9593 - val_loss: 0.1204 - val_acc: 0.9639\n",
      "Epoch 8/15\n",
      "52154/52154 [==============================] - 745s 14ms/step - loss: 0.1160 - acc: 0.9647 - val_loss: 0.1371 - val_acc: 0.9480\n",
      "Epoch 9/15\n",
      "52154/52154 [==============================] - 652s 12ms/step - loss: 0.1140 - acc: 0.9642 - val_loss: 0.1088 - val_acc: 0.9680\n",
      "Epoch 10/15\n",
      "52154/52154 [==============================] - 1401s 27ms/step - loss: 0.1021 - acc: 0.9691 - val_loss: 0.1116 - val_acc: 0.9684\n",
      "Epoch 11/15\n",
      "52154/52154 [==============================] - 747s 14ms/step - loss: 0.0982 - acc: 0.9703 - val_loss: 0.1135 - val_acc: 0.9668\n",
      "Epoch 12/15\n",
      "52154/52154 [==============================] - 695s 13ms/step - loss: 0.0932 - acc: 0.9725 - val_loss: 0.0966 - val_acc: 0.9720\n",
      "Epoch 13/15\n",
      "52154/52154 [==============================] - 718s 14ms/step - loss: 0.0883 - acc: 0.9733 - val_loss: 0.1033 - val_acc: 0.9714\n",
      "Epoch 14/15\n",
      "52154/52154 [==============================] - 684s 13ms/step - loss: 0.0837 - acc: 0.9750 - val_loss: 0.0966 - val_acc: 0.9715\n",
      "Epoch 15/15\n",
      "52154/52154 [==============================] - 662s 13ms/step - loss: 0.0832 - acc: 0.9747 - val_loss: 0.0876 - val_acc: 0.9744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a16841ed0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input more epochs here Peter\n",
    "\n",
    "batch_size=1000\n",
    "model.fit(np.array(train_X), np.array(train_Y),batch_size=batch_size,nb_epoch=15,validation_data=(np.array(test_X), np.array(test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13302/13302 [==============================] - 81s 6ms/step\n",
      "Test score: 0.08758377855515645\n",
      "Test accuracy: 0.9743647571793715\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(np.array(test_X), np.array(test_Y))\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name whose gender you want to know: melissa\n",
      "The name whose gender you want to know is: melissa\n"
     ]
    }
   ],
   "source": [
    "request = raw_input(\"Enter the name whose gender you want to know: \")\n",
    "print('The name whose gender you want to know is:', request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['melissa']\n",
      "[[0.01798168 0.98201835]]\n",
      "Female\n"
     ]
    }
   ],
   "source": [
    "name=[]\n",
    "name.append(request)\n",
    "print (name)\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "print (pred)\n",
    "if pred[0,0] > 0.5:\n",
    "    print (\"Male\")\n",
    "else:\n",
    "    print (\"Female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and data\n",
    "model.save_weights('gender_model_18_epochs',overwrite=True)\n",
    "train.to_csv(\"train_split_18_epochs.csv\")\n",
    "test.to_csv(\"test_split_18_epochs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the ethnicity! Similar process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "b               1\n",
       "black       35042\n",
       "hispanic     4381\n",
       "whit            1\n",
       "white       26030\n",
       "Name: first_name, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1.groupby('race')['first_name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        hispanic\n",
      "1        hispanic\n",
      "2        hispanic\n",
      "3        hispanic\n",
      "4        hispanic\n",
      "5        hispanic\n",
      "6        hispanic\n",
      "7        hispanic\n",
      "8        hispanic\n",
      "9        hispanic\n",
      "10       hispanic\n",
      "11       hispanic\n",
      "12       hispanic\n",
      "13       hispanic\n",
      "14       hispanic\n",
      "15       hispanic\n",
      "16       hispanic\n",
      "17       hispanic\n",
      "18       hispanic\n",
      "19       hispanic\n",
      "20       hispanic\n",
      "21       hispanic\n",
      "22       hispanic\n",
      "23       hispanic\n",
      "24       hispanic\n",
      "25       hispanic\n",
      "26       hispanic\n",
      "27       hispanic\n",
      "28       hispanic\n",
      "29       hispanic\n",
      "           ...   \n",
      "65466       white\n",
      "65467       white\n",
      "65468       white\n",
      "65469       white\n",
      "65470       white\n",
      "65471       white\n",
      "65472       white\n",
      "65473       white\n",
      "65474       white\n",
      "65475       white\n",
      "65476       white\n",
      "65477       white\n",
      "65478       white\n",
      "65479       white\n",
      "65480       white\n",
      "65481       white\n",
      "65482       white\n",
      "65483       white\n",
      "65484       white\n",
      "65485       white\n",
      "65486       white\n",
      "65487       white\n",
      "65488       white\n",
      "65489       white\n",
      "65490       white\n",
      "65491       white\n",
      "65492       white\n",
      "65493       white\n",
      "65494       white\n",
      "65495       white\n",
      "Name: race, Length: 65456, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "race\n",
       "black       35043\n",
       "hispanic     4381\n",
       "white       26031\n",
       "Name: first_name, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tidy data\n",
    "\n",
    "input1['race'] = [w.replace('whit', 'white') for w in input1['race']]\n",
    "input1['race'] = [w.replace('b', 'black') for w in input1['race']]\n",
    "\n",
    "input1.groupby('race')['first_name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = input1['first_name']\n",
    "race = input1['race']\n",
    "vocab = set(' '.join([str(i) for i in names]))\n",
    "vocab.add('END')\n",
    "len_vocab = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' ', '-', '.', '0', 'END', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z'])\n",
      "vocab length is  31\n",
      "length of input is  65456\n"
     ]
    }
   ],
   "source": [
    "print(vocab)\n",
    "print(\"vocab length is \",len_vocab)\n",
    "print (\"length of input is \",len(input1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '-': 1, '.': 2, '0': 3, 'END': 4, 'a': 5, 'c': 6, 'b': 7, 'e': 8, 'd': 9, 'g': 10, 'f': 11, 'i': 12, 'h': 13, 'k': 14, 'j': 15, 'm': 16, 'l': 17, 'o': 18, 'n': 19, 'q': 20, 'p': 21, 's': 22, 'r': 23, 'u': 24, 't': 25, 'w': 26, 'v': 27, 'y': 28, 'x': 29, 'z': 30}\n"
     ]
    }
   ],
   "source": [
    "char_index = dict((c, i) for i, c in enumerate(vocab))\n",
    "print (char_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "msk = np.random.rand(len(input1)) < 0.8\n",
    "train = input1[msk]\n",
    "test = input1[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1              ana\n",
      "2           miriam\n",
      "3           ivette\n",
      "4            saray\n",
      "5           niurka\n",
      "6            maria\n",
      "7         merienne\n",
      "8        rosalinda\n",
      "9         migdalia\n",
      "10          marina\n",
      "11          carmen\n",
      "14         melissa\n",
      "17        ivelisse\n",
      "18             ana\n",
      "19          emilia\n",
      "20          connie\n",
      "22        samantha\n",
      "23       elizabeth\n",
      "24            ines\n",
      "26          ivette\n",
      "27          gloria\n",
      "28           linda\n",
      "29          josefa\n",
      "30        graciela\n",
      "31             ada\n",
      "34        jennifer\n",
      "35         mariely\n",
      "36          glenny\n",
      "37           yanet\n",
      "39         johanna\n",
      "           ...    \n",
      "65462      richard\n",
      "65463      richard\n",
      "65464        roger\n",
      "65465       stacey\n",
      "65466      timothy\n",
      "65467         todd\n",
      "65468       victor\n",
      "65469      zachary\n",
      "65470        lukas\n",
      "65471      kenneth\n",
      "65472        brent\n",
      "65473      timothy\n",
      "65474       george\n",
      "65476      freeman\n",
      "65477      michael\n",
      "65478      william\n",
      "65479       walter\n",
      "65480      richard\n",
      "65481      kenneth\n",
      "65482        roger\n",
      "65483        danny\n",
      "65484        devin\n",
      "65485      william\n",
      "65486        mikel\n",
      "65487      william\n",
      "65488       andrew\n",
      "65490      stephen\n",
      "65492       george\n",
      "65493     theodore\n",
      "65495      gregory\n",
      "Name: first_name, Length: 52408, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#take input upto max and truncate rest\n",
    "#encode to vector space(one hot encoding)\n",
    "#padd 'END' to shorter sequences\n",
    "print (train.first_name)\n",
    "train_X = []\n",
    "trunc_train_name = [str(i)[0:30] for i in train.first_name]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [char_index[j] for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(char_index[\"END\"])\n",
    "    train_X.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52408, 30)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take input upto max and truncate rest\n",
    "#encode to vector space(one hot encoding)\n",
    "#add 'END' to shorter sequences\n",
    "#also convert each index to one-hot encoding\n",
    "train_X = []\n",
    "train_Y = []\n",
    "trunc_train_name = [str(i)[0:maxlen] for i in train.first_name]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    train_X.append(tmp)\n",
    "for i in train.race:\n",
    "    if i == 'white':\n",
    "        train_Y.append([1,0,0])\n",
    "    elif i == 'black':\n",
    "        train_Y.append([0,1,0])\n",
    "    elif i== 'hispanic':\n",
    "        train_Y.append([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "#build the model: 2 stacked LSTM\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen,39)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3))     #change to 3 (from 2) as we now have 3 outputs, white, black or hispanic\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []\n",
    "test_Y = []\n",
    "trunc_test_name = [str(i)[0:maxlen] for i in test.first_name]\n",
    "for i in trunc_test_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    test_X.append(tmp)\n",
    "for i in test.race:\n",
    "    if i == 'white':\n",
    "        test_Y.append([1,0,0])\n",
    "    elif i == 'black':\n",
    "        test_Y.append([0,1,0])\n",
    "    elif i == 'hispanic':\n",
    "        test_Y.append([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13048, 30, 39)\n",
      "(13048, 3)\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(test_X).shape)\n",
    "print(np.asarray(test_Y).shape)\n",
    "print (maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52408 samples, validate on 13048 samples\n",
      "Epoch 1/18\n",
      "52408/52408 [==============================] - 839s 16ms/step - loss: 0.8841 - acc: 0.5337 - val_loss: 0.8783 - val_acc: 0.5391\n",
      "Epoch 2/18\n",
      "52408/52408 [==============================] - 680s 13ms/step - loss: 0.8668 - acc: 0.5355 - val_loss: 0.8803 - val_acc: 0.5142\n",
      "Epoch 3/18\n",
      "52408/52408 [==============================] - 683s 13ms/step - loss: 0.8603 - acc: 0.5390 - val_loss: 0.8489 - val_acc: 0.5383\n",
      "Epoch 4/18\n",
      "52408/52408 [==============================] - 652s 12ms/step - loss: 0.8344 - acc: 0.5559 - val_loss: 0.8270 - val_acc: 0.5594\n",
      "Epoch 5/18\n",
      "52408/52408 [==============================] - 732s 14ms/step - loss: 0.8186 - acc: 0.5660 - val_loss: 0.8092 - val_acc: 0.5571\n",
      "Epoch 6/18\n",
      "52408/52408 [==============================] - 637s 12ms/step - loss: 0.8024 - acc: 0.5779 - val_loss: 0.7967 - val_acc: 0.5809\n",
      "Epoch 7/18\n",
      "52408/52408 [==============================] - 633s 12ms/step - loss: 0.7903 - acc: 0.5886 - val_loss: 0.7881 - val_acc: 0.5767\n",
      "Epoch 8/18\n",
      "52408/52408 [==============================] - 635s 12ms/step - loss: 0.7773 - acc: 0.5981 - val_loss: 0.7729 - val_acc: 0.6020\n",
      "Epoch 9/18\n",
      "52408/52408 [==============================] - 634s 12ms/step - loss: 0.7664 - acc: 0.6110 - val_loss: 0.7666 - val_acc: 0.6059\n",
      "Epoch 10/18\n",
      "52408/52408 [==============================] - 701s 13ms/step - loss: 0.7586 - acc: 0.6154 - val_loss: 0.7621 - val_acc: 0.6058\n",
      "Epoch 11/18\n",
      "52408/52408 [==============================] - 730s 14ms/step - loss: 0.7516 - acc: 0.6199 - val_loss: 0.7511 - val_acc: 0.6122\n",
      "Epoch 12/18\n",
      "52408/52408 [==============================] - 736s 14ms/step - loss: 0.7444 - acc: 0.6258 - val_loss: 0.7433 - val_acc: 0.6209\n",
      "Epoch 13/18\n",
      "52408/52408 [==============================] - 807s 15ms/step - loss: 0.7353 - acc: 0.6334 - val_loss: 0.7402 - val_acc: 0.6212\n",
      "Epoch 14/18\n",
      "52408/52408 [==============================] - 700s 13ms/step - loss: 0.7296 - acc: 0.6365 - val_loss: 0.7335 - val_acc: 0.6277\n",
      "Epoch 15/18\n",
      "52408/52408 [==============================] - 810s 15ms/step - loss: 0.7230 - acc: 0.6410 - val_loss: 0.7339 - val_acc: 0.6212\n",
      "Epoch 16/18\n",
      "52408/52408 [==============================] - 739s 14ms/step - loss: 0.7168 - acc: 0.6477 - val_loss: 0.7249 - val_acc: 0.6399\n",
      "Epoch 17/18\n",
      "52408/52408 [==============================] - 728s 14ms/step - loss: 0.7100 - acc: 0.6492 - val_loss: 0.7176 - val_acc: 0.6420\n",
      "Epoch 18/18\n",
      "52408/52408 [==============================] - 772s 15ms/step - loss: 0.7064 - acc: 0.6511 - val_loss: 0.7097 - val_acc: 0.6463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a30b97b10>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1000\n",
    "model.fit(np.array(train_X), np.array(train_Y),batch_size=batch_size,nb_epoch=18,validation_data=(np.array(test_X), np.array(test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13048/13048 [==============================] - 86s 7ms/step\n",
      "Test score: 0.7097495917086949\n",
      "Test accuracy: 0.6463059472716125\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(np.array(test_X), np.array(test_Y))\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and data\n",
    "model.save_weights('race_model_18_epochs_try2',overwrite=True)\n",
    "train.to_csv(\"train_split_18_epochs.csv\")\n",
    "test.to_csv(\"test_split_18_epochs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name whose race you want to know: tony\n",
      "The name whose race you want to know is: tony\n"
     ]
    }
   ],
   "source": [
    "request = raw_input(\"Enter the name whose race you want to know: \")\n",
    "print('The name whose race you want to know is:', request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tony']\n",
      "[[0.30031165 0.6664009  0.03328747]]\n",
      "black\n"
     ]
    }
   ],
   "source": [
    "name=[]\n",
    "name.append(request)\n",
    "print (name)\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "print (pred)\n",
    "if pred[0,0] > 0.3333:    #note: this if loop is not right, see below how I've corrected it for the combined result\n",
    "    print (\"white\")\n",
    "elif pred[0,1] > 0.3333:\n",
    "    print (\"black\")\n",
    "elif pred[0,2] > 0.3333:\n",
    "    print (\"hispanic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our accuracy is 65% which isn't bad but not as good as for gender. We could now refine the architecture of our model to see if we can improve our accuracy. But this seems okay for now. Let's combine our two results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ethnicity = keras.models.clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model_gender = Sequential()\n",
    "model_gender.add(LSTM(512, return_sequences=True, input_shape=(maxlen,39)))\n",
    "model_gender.add(Dropout(0.2))\n",
    "model_gender.add(LSTM(512, return_sequences=False))\n",
    "model_gender.add(Dropout(0.2))\n",
    "model_gender.add(Dense(2))     #change to 2 (from 3) as we now have 2 outputs, m or f\n",
    "model_gender.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 30, 512)           1130496   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 3,231,235\n",
      "Trainable params: 3,231,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_ethnicity.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 30, 512)           1130496   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,230,722\n",
      "Trainable params: 3,230,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_gender.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gender.save_weights('gender_model_18_epochs',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gender.load_weights('gender_model_18_epochs', by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ethnicity.load_weights('race_model_18_epochs', by_name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we're ready to ask for user input! Let's give it a go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name whose ethnicity and gender you want to know: daniel\n",
      "The name whose race you want to know is: daniel\n"
     ]
    }
   ],
   "source": [
    "request = raw_input(\"Enter the name whose ethnicity and gender you want to know: \")\n",
    "print('The name whose race you want to know is:', request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daniel']\n",
      "[[0.7436051  0.15517457 0.10122035]]\n",
      "white\n",
      "[[0.988057   0.01194294]]\n",
      "Male\n"
     ]
    }
   ],
   "source": [
    "name=[]\n",
    "name.append(request)\n",
    "print (name)\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred_ethnicity=model_ethnicity.predict(np.asarray(X))\n",
    "print (pred_ethnicity)\n",
    "if pred_ethnicity[0,0] > pred_ethnicity[0,1] and pred_ethnicity[0,0] > pred_ethnicity[0,2]:\n",
    "    print (\"White\")\n",
    "elif pred_ethnicity[0,1] > pred_ethnicity[0,0] and pred_ethnicity[0,1] > pred_ethnicity[0,2]:\n",
    "    print (\"Black\")\n",
    "elif pred_ethnicity[0,2] > pred_ethnicity[0,0] and pred_ethnicity[0,2] > pred_ethnicity[0,1]:\n",
    "    print (\"Hispanic\")\n",
    "    \n",
    "pred_gender=model_gender.predict(np.asarray(X))\n",
    "print (pred_gender)\n",
    "if pred_gender[0,0] > 0.5:\n",
    "    print (\"Male\")\n",
    "else:\n",
    "    print (\"Female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have run a few tests and seems to work quite well. As I mentioned above I could now look at adapting the architecture for the ethnicity model to see if I can get the accuracy higher. But it seems to give good results as it is so let's leave it for now (can discuss this when we meet if you like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
